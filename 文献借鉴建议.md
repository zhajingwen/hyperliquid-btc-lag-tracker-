# åŸºäºæ–‡çŒ®ç ”ç©¶çš„é¡¹ç›®æ”¹è¿›å»ºè®®

æœ¬æ–‡æ¡£åŸºäº **Leung & Nguyen (2019)** å’Œ **Tadi & Witzany (2025)** ä¸¤ä»½é‡è¦æ–‡çŒ®ï¼Œç»“åˆå½“å‰é¡¹ç›®çš„å®é™…å®ç°ï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å€Ÿé‰´å»ºè®®ã€‚

---

## ä¸€ã€å½“å‰é¡¹ç›®ç°çŠ¶åˆ†æ

### 1.1 ç°æœ‰æŠ€æœ¯æ ˆ

- **ç›¸å…³æ€§åˆ†æ**: çš®å°”é€Šç›¸å…³ç³»æ•°ï¼ˆPearson Correlationï¼‰
- **æ—¶é—´ç»´åº¦**: è·¨å‘¨æœŸåˆ†æï¼ˆ5m/7d vs 1m/1dï¼‰
- **å»¶è¿Ÿä¼˜åŒ–**: æœç´¢æœ€ä¼˜å»¶è¿Ÿ Ï„* âˆˆ [0, 3]
- **æ³¢åŠ¨è¯„ä¼°**: Beta ç³»æ•°ï¼ˆÎ² â‰¥ 1.0ï¼‰
- **å¼‚å¸¸å€¼å¤„ç†**: Winsorizationï¼ˆ0.1% - 99.9%åˆ†ä½æ•°ï¼‰
- **é˜ˆå€¼åˆ¤æ–­**: é™æ€é˜ˆå€¼ï¼ˆé•¿æœŸ>0.6, çŸ­æœŸ<0.4, å·®å€¼>0.38ï¼‰

### 1.2 é¡¹ç›®å®šä½

- **å½“å‰é˜¶æ®µ**: ç ”ç©¶ä¸æ¢ç´¢é˜¶æ®µ
- **æ ¸å¿ƒç›®æ ‡**: è¯†åˆ«å¼‚å¸¸å¸ç§ï¼Œå‘ç°å¥—åˆ©æœºä¼š
- **è¾“å‡º**: é£ä¹¦å‘Šè­¦é€šçŸ¥ï¼Œä¸æ¶‰åŠå®é™…äº¤æ˜“

---

## äºŒã€ä»æ–‡çŒ®ä¸­çš„å…·ä½“å€Ÿé‰´ç‚¹

### 2.1 ä» Leung & Nguyen (2019) çš„å€Ÿé‰´

#### ğŸ” å€Ÿé‰´ç‚¹1: å¼•å…¥åæ•´æ£€éªŒå¢å¼ºé•¿æœŸç›¸å…³æ€§éªŒè¯

**å½“å‰é—®é¢˜**:
- ä»…ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°åˆ¤æ–­é•¿æœŸç›¸å…³æ€§ï¼ˆÏ > 0.6ï¼‰
- ç›¸å…³ç³»æ•°åªèƒ½åæ˜ çº¿æ€§ç›¸å…³ï¼Œæ— æ³•éªŒè¯ç»Ÿè®¡æ˜¾è‘—æ€§
- å¯èƒ½å­˜åœ¨ä¼ªç›¸å…³æ€§ï¼ˆspurious correlationï¼‰

**æ–‡çŒ®æ–¹æ³•**:
- ä½¿ç”¨ **Engle-Granger ä¸¤æ­¥æ³•**æ£€éªŒåæ•´å…³ç³»
- ä½¿ç”¨ **Johansen æ£€éªŒ**å¤„ç†å¤šå˜é‡æƒ…å†µ

**å®æ–½å»ºè®®**:

```python
# åœ¨ hyperliquid_analyzer.py ä¸­æ–°å¢åæ•´æ£€éªŒæ¨¡å—

from statsmodels.tsa.stattools import coint, adfuller
from statsmodels.tsa.vector_ar.vecm import coint_johansen

class DelayCorrelationAnalyzer:
    # ... ç°æœ‰ä»£ç  ...
    
    def _test_cointegration(self, btc_prices: np.ndarray, alt_prices: np.ndarray) -> dict:
        """
        ä½¿ç”¨Engle-Grangeræ–¹æ³•æ£€éªŒåæ•´å…³ç³»
        
        Args:
            btc_prices: BTCä»·æ ¼åºåˆ—
            alt_prices: å±±å¯¨å¸ä»·æ ¼åºåˆ—
            
        Returns:
            {
                'cointegrated': bool,      # æ˜¯å¦åæ•´
                'pvalue': float,           # på€¼
                'test_statistic': float,   # æ£€éªŒç»Ÿè®¡é‡
                'critical_values': dict    # ä¸´ç•Œå€¼
            }
        """
        try:
            # Engle-Granger åæ•´æ£€éªŒ
            score, pvalue, _ = coint(alt_prices, btc_prices)
            
            # 5%æ˜¾è‘—æ€§æ°´å¹³
            is_cointegrated = pvalue < 0.05
            
            logger.debug(
                f"åæ•´æ£€éªŒ | på€¼: {pvalue:.4f} | "
                f"ç»Ÿè®¡é‡: {score:.4f} | åæ•´: {is_cointegrated}"
            )
            
            return {
                'cointegrated': is_cointegrated,
                'pvalue': pvalue,
                'test_statistic': score
            }
        except Exception as e:
            logger.warning(f"åæ•´æ£€éªŒå¤±è´¥: {e}")
            return {'cointegrated': False, 'pvalue': 1.0, 'test_statistic': 0.0}
    
    def _enhanced_anomaly_detection(self, btc_prices: np.ndarray, alt_prices: np.ndarray, 
                                    long_term_corr: float) -> bool:
        """
        å¢å¼ºçš„å¼‚å¸¸æ£€æµ‹ï¼šç»“åˆç›¸å…³ç³»æ•°å’Œåæ•´æ£€éªŒ
        
        åªæœ‰å½“åŒæ—¶æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ—¶æ‰è®¤ä¸ºæ˜¯çœŸæ­£çš„é•¿æœŸå…³ç³»ï¼š
        1. ç›¸å…³ç³»æ•° > 0.6ï¼ˆç°æœ‰æ¡ä»¶ï¼‰
        2. åæ•´æ£€éªŒé€šè¿‡ï¼ˆæ–°å¢æ¡ä»¶ï¼‰
        """
        # ç°æœ‰æ¡ä»¶ï¼šé•¿æœŸé«˜ç›¸å…³
        if long_term_corr < self.LONG_TERM_CORR_THRESHOLD:
            return False
        
        # æ–°å¢æ¡ä»¶ï¼šåæ•´æ£€éªŒ
        coint_result = self._test_cointegration(btc_prices, alt_prices)
        if not coint_result['cointegrated']:
            logger.info(
                f"åæ•´æ£€éªŒæœªé€šè¿‡ï¼Œè¿‡æ»¤ | ç›¸å…³ç³»æ•°: {long_term_corr:.4f} | "
                f"på€¼: {coint_result['pvalue']:.4f}"
            )
            return False
        
        return True
```

**ä¼˜åŠ¿**:
- âœ… æä¾›ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯ï¼Œé¿å…ä¼ªç›¸å…³æ€§
- âœ… ä¸ç°æœ‰é€»è¾‘å…¼å®¹ï¼Œå¯ä»¥ä½œä¸ºé¢å¤–çš„è¿‡æ»¤æ¡ä»¶
- âœ… å®æ–½ç®€å•ï¼Œåªéœ€åœ¨ç°æœ‰æ£€æµ‹é€»è¾‘ä¸­æ·»åŠ åæ•´æ£€éªŒ

**æ³¨æ„äº‹é¡¹**:
- åæ•´æ£€éªŒéœ€è¦è¶³å¤Ÿçš„æ•°æ®é‡ï¼ˆå»ºè®®è‡³å°‘100ä¸ªæ•°æ®ç‚¹ï¼‰
- æ£€éªŒç»“æœå¯èƒ½éšæ—¶é—´å˜åŒ–ï¼Œéœ€è¦å®šæœŸé‡æ–°éªŒè¯

---

#### ğŸ“Š å€Ÿé‰´ç‚¹2: å¼•å…¥ä»·å·®è¿‡ç¨‹ï¼ˆSpread Processï¼‰æ¦‚å¿µ

**å½“å‰æ–¹æ³•**:
- ç›´æ¥ä½¿ç”¨æ”¶ç›Šç‡è®¡ç®—ç›¸å…³ç³»æ•°
- å¯èƒ½å­˜åœ¨éå¹³ç¨³æ€§é—®é¢˜

**æ–‡çŒ®æ–¹æ³•**:
- ä½¿ç”¨**å¹³ç¨³ä»·å·®è¿‡ç¨‹**: `S^i_t = P^i_t - Î²Ì‚^i Ã— P^BTC_t`
- ä»·å·®è¿‡ç¨‹æ›´å®¹æ˜“æ»¡è¶³å¹³ç¨³æ€§å‡è®¾

**å®æ–½å»ºè®®**:

```python
def _calculate_spread_process(self, btc_prices: np.ndarray, 
                              alt_prices: np.ndarray) -> tuple[np.ndarray, float]:
    """
    è®¡ç®—ä»·å·®è¿‡ç¨‹ S_t = P_alt - Î² Ã— P_btc
    
    Args:
        btc_prices: BTCä»·æ ¼åºåˆ—
        alt_prices: å±±å¯¨å¸ä»·æ ¼åºåˆ—
        
    Returns:
        (spread_process, beta_coef): ä»·å·®åºåˆ—å’Œå›å½’ç³»æ•°
    """
    # ä½¿ç”¨çº¿æ€§å›å½’ä¼°è®¡ Î²
    from sklearn.linear_model import LinearRegression
    
    X = btc_prices.reshape(-1, 1)
    y = alt_prices
    
    model = LinearRegression()
    model.fit(X, y)
    beta_coef = model.coef_[0]
    
    # è®¡ç®—ä»·å·®è¿‡ç¨‹
    spread = alt_prices - beta_coef * btc_prices
    
    return spread, beta_coef

def _analyze_spread_correlation(self, btc_prices: np.ndarray, 
                                alt_prices: np.ndarray) -> float:
    """
    åŸºäºä»·å·®è¿‡ç¨‹çš„ç›¸å…³æ€§åˆ†æï¼ˆæ›¿ä»£ç›´æ¥æ”¶ç›Šç‡ç›¸å…³æ€§ï¼‰
    
    ä¼˜åŠ¿ï¼š
    1. ä»·å·®è¿‡ç¨‹æ›´å¯èƒ½æ»¡è¶³å¹³ç¨³æ€§
    2. æ›´å¥½åœ°æ•æ‰é•¿æœŸå‡è¡¡å…³ç³»
    3. ä¸åæ•´ç†è®ºä¸€è‡´
    """
    spread, _ = self._calculate_spread_process(btc_prices, alt_prices)
    
    # è®¡ç®—ä»·å·®åºåˆ—çš„è‡ªç›¸å…³æ€§æˆ–å¹³ç¨³æ€§
    # å¯ä»¥ä½¿ç”¨ä»·å·®çš„æ–¹å·®ä½œä¸ºæ³¢åŠ¨æ€§æŒ‡æ ‡
    spread_volatility = np.std(spread)
    
    # æˆ–è€…è®¡ç®—ä»·å·®ä¸BTCä»·æ ¼çš„ç›¸å…³æ€§
    # è¿™é‡Œå¯ä»¥çµæ´»å®šä¹‰ç›¸å…³æ€§åº¦é‡
    
    return spread_volatility
```

**é€‚ç”¨åœºæ™¯**:
- ä½œä¸ºç°æœ‰ç›¸å…³ç³»æ•°çš„è¡¥å……æŒ‡æ ‡
- ç”¨äºéªŒè¯é•¿æœŸå…³ç³»çš„ç¨³å®šæ€§
- ä¸ºåç»­å¼•å…¥Copulaæ–¹æ³•åšå‡†å¤‡

---

### 2.2 ä» Tadi & Witzany (2025) çš„å€Ÿé‰´

#### ğŸ”— å€Ÿé‰´ç‚¹3: å¼•å…¥Kendall's Ï„ä½œä¸ºç¨³å¥æ€§æŒ‡æ ‡

**å½“å‰é—®é¢˜**:
- çš®å°”é€Šç›¸å…³ç³»æ•°å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ
- å‡è®¾æ•°æ®æœä»æ­£æ€åˆ†å¸ƒ
- åªæ•æ‰çº¿æ€§ç›¸å…³æ€§

**æ–‡çŒ®æ–¹æ³•**:
- ä½¿ç”¨ **Kendall's Ï„ï¼ˆKendall's Tauï¼‰**ä½œä¸ºç›¸å…³æ€§åº¦é‡
- å¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥ï¼Œä¸è¦æ±‚æ­£æ€åˆ†å¸ƒ
- å¯ä»¥æ•æ‰éçº¿æ€§å•è°ƒå…³ç³»

**å®æ–½å»ºè®®**:

```python
from scipy.stats import kendalltau

class DelayCorrelationAnalyzer:
    # ... ç°æœ‰ä»£ç  ...
    
    def _calculate_kendall_tau(self, x: np.ndarray, y: np.ndarray) -> tuple[float, float]:
        """
        è®¡ç®—Kendall's Ï„ç›¸å…³ç³»æ•°
        
        Args:
            x: ç¬¬ä¸€ä¸ªåºåˆ—ï¼ˆå¦‚BTCæ”¶ç›Šç‡ï¼‰
            y: ç¬¬äºŒä¸ªåºåˆ—ï¼ˆå¦‚å±±å¯¨å¸æ”¶ç›Šç‡ï¼‰
            
        Returns:
            (tau, pvalue): Kendall's Ï„å€¼å’Œpå€¼
        """
        tau, pvalue = kendalltau(x, y)
        return tau, pvalue
    
    def find_optimal_delay_with_kendall(self, btc_ret: np.ndarray, 
                                       alt_ret: np.ndarray, 
                                       max_lag: int = 3) -> tuple[int, list, float, float]:
        """
        ä½¿ç”¨Kendall's Ï„å¯»æ‰¾æœ€ä¼˜å»¶è¿Ÿï¼ˆä½œä¸ºPearsonç›¸å…³ç³»æ•°çš„è¡¥å……ï¼‰
        
        Returns:
            (tau_star, tau_list, max_tau, max_corr): 
            æœ€ä¼˜å»¶è¿Ÿã€å»¶è¿Ÿåˆ—è¡¨ã€æœ€å¤§Kendall's Ï„ã€æœ€å¤§Pearsonç›¸å…³ç³»æ•°
        """
        tau_list = []
        corr_list = []
        
        for lag in range(max_lag + 1):
            if lag == 0:
                x = btc_ret
                y = alt_ret
            else:
                x = btc_ret[:-lag]
                y = alt_ret[lag:]
            
            # è®¡ç®—Kendall's Ï„
            tau, _ = self._calculate_kendall_tau(x, y)
            tau_list.append(tau)
            
            # åŒæ—¶è®¡ç®—Pearsonç›¸å…³ç³»æ•°ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            corr = np.corrcoef(x, y)[0, 1]
            corr_list.append(corr)
        
        # æ‰¾åˆ°Kendall's Ï„æœ€å¤§çš„å»¶è¿Ÿ
        max_tau_idx = np.argmax(np.abs(tau_list))
        tau_star = max_tau_idx
        max_tau = tau_list[tau_star]
        max_corr = corr_list[tau_star]
        
        return tau_star, tau_list, max_tau, max_corr
```

**é›†æˆåˆ°ç°æœ‰ä»£ç **:

```python
# åœ¨ _analyze_single_combination æ–¹æ³•ä¸­
def _analyze_single_combination(self, coin: str, timeframe: str, period: str, 
                                alt_df: pd.DataFrame | None = None) -> tuple | None:
    # ... ç°æœ‰ä»£ç  ...
    
    # åŸæœ‰æ–¹æ³•ï¼šä½¿ç”¨Pearsonç›¸å…³ç³»æ•°
    tau_star, corrs, max_corr, beta = self.find_optimal_delay(...)
    
    # æ–°å¢ï¼šåŒæ—¶è®¡ç®—Kendall's Ï„
    tau_star_kendall, tau_list, max_kendall_tau, _ = \
        self.find_optimal_delay_with_kendall(btc_ret, alt_ret, max_lag=3)
    
    # å¯ä»¥å°†Kendall's Ï„ä½œä¸ºé¢å¤–çš„è¿‡æ»¤æ¡ä»¶æˆ–ç½®ä¿¡åº¦æŒ‡æ ‡
    # ä¾‹å¦‚ï¼šåªæœ‰å½“Kendall's Ï„å’ŒPearsonç›¸å…³ç³»æ•°éƒ½æ»¡è¶³æ¡ä»¶æ—¶æ‰è®¤ä¸ºæœ‰æ•ˆ
    
    return (max_corr, timeframe, period, tau_star, beta, max_kendall_tau)  # æ‰©å±•è¿”å›å€¼
```

**ä¼˜åŠ¿**:
- âœ… å¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥ï¼ˆä¸Winsorizationäº’è¡¥ï¼‰
- âœ… ä¸éœ€è¦æ­£æ€åˆ†å¸ƒå‡è®¾
- âœ… å¯ä»¥æ•æ‰å•è°ƒä½†éçº¿æ€§çš„å…³ç³»
- âœ… å®æ–½ç®€å•ï¼Œscipyå·²æœ‰å®ç°

---

#### ğŸ¯ å€Ÿé‰´ç‚¹4: å¼•å…¥Copulaæ–¹æ³•å»ºæ¨¡éçº¿æ€§ä¾èµ–æ€§ï¼ˆé«˜çº§ï¼‰

**å½“å‰æ–¹æ³•**:
- åªä½¿ç”¨çº¿æ€§ç›¸å…³ç³»æ•°
- æ— æ³•æ•æ‰å°¾éƒ¨ä¾èµ–æ€§ï¼ˆtail dependenceï¼‰
- æ— æ³•å»ºæ¨¡éå¯¹ç§°ç›¸å…³æ€§

**æ–‡çŒ®æ–¹æ³•**:
- ä½¿ç”¨Copulaå»ºæ¨¡è”åˆåˆ†å¸ƒ
- æ•æ‰éçº¿æ€§ä¾èµ–æ€§å’Œå°¾éƒ¨é£é™©
- å¯ä»¥ç”Ÿæˆæ›´ç²¾ç¡®çš„äº¤æ˜“ä¿¡å·

**å®æ–½å»ºè®®ï¼ˆåˆ†é˜¶æ®µï¼‰**:

**é˜¶æ®µ1: å¼•å…¥åŸºç¡€Copulaè¯„ä¼°ï¼ˆå¯è¡Œæ€§éªŒè¯ï¼‰**

```python
# éœ€è¦å®‰è£…: pip install copulae

from copulae import GaussianCopula, StudentCopula
from copulae.core import pseudo_observations

class DelayCorrelationAnalyzer:
    def _estimate_copula(self, btc_ret: np.ndarray, alt_ret: np.ndarray) -> dict:
        """
        ä¼°è®¡Copulaå‚æ•°ï¼Œè¯„ä¼°éçº¿æ€§ä¾èµ–æ€§
        
        è¿™æ˜¯ä¸€ä¸ªæ¢ç´¢æ€§åŠŸèƒ½ï¼Œå¯ä»¥å…ˆè¯„ä¼°å¯è¡Œæ€§
        ä¸éœ€è¦ç«‹å³ç”¨äºä¿¡å·ç”Ÿæˆ
        
        Returns:
            {
                'gaussian_corr': float,      # é«˜æ–¯Copulaçš„å‚æ•°
                'student_corr': float,       # Student-t Copulaçš„ç›¸å…³å‚æ•°
                'tail_dependence': float     # å°¾éƒ¨ä¾èµ–æ€§ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
            }
        """
        try:
            # è½¬æ¢ä¸ºä¼ªè§‚æµ‹å€¼ï¼ˆuniform marginalsï¼‰
            u = pseudo_observations(np.column_stack([btc_ret, alt_ret]))
            
            # æ‹Ÿåˆé«˜æ–¯Copula
            gaussian_cop = GaussianCopula(dim=2)
            gaussian_cop.fit(u)
            
            # å¯ä»¥è¿›ä¸€æ­¥æ‹ŸåˆStudent-t Copulaï¼ˆæ•æ‰å°¾éƒ¨ä¾èµ–æ€§ï¼‰
            # student_cop = StudentCopula(dim=2)
            # student_cop.fit(u)
            
            # æå–ç›¸å…³æ€§å‚æ•°
            gaussian_corr = gaussian_cop.params['corr'][0, 1]
            
            logger.debug(f"Copulaä¼°è®¡ | é«˜æ–¯Copulaç›¸å…³æ€§: {gaussian_corr:.4f}")
            
            return {
                'gaussian_corr': gaussian_corr,
                'method': 'gaussian'
            }
        except Exception as e:
            logger.warning(f"Copulaä¼°è®¡å¤±è´¥: {e}")
            return {'gaussian_corr': 0.0, 'method': 'failed'}
```

**é˜¶æ®µ2: åŸºäºCopulaæ¡ä»¶æ¦‚ç‡çš„ä¿¡å·ç”Ÿæˆ**

```python
def _generate_copula_signal(self, btc_ret: np.ndarray, alt_ret: np.ndarray,
                           copula_model) -> dict:
    """
    åŸºäºCopulaæ¡ä»¶æ¦‚ç‡ç”Ÿæˆäº¤æ˜“ä¿¡å·
    
    æ–‡çŒ®ä¸­çš„æ–¹æ³•ï¼š
    - è®¡ç®—æ¡ä»¶æ¦‚ç‡ P(U_1 â‰¤ u_1 | U_2 = u_2)
    - å½“æ¦‚ç‡ä½äºé˜ˆå€¼æ—¶å¼€ä»“
    - å½“æ¦‚ç‡å›åˆ°é˜ˆå€¼æ—¶å¹³ä»“
    """
    # è½¬æ¢ä¸ºä¼ªè§‚æµ‹å€¼
    u = pseudo_observations(np.column_stack([btc_ret, alt_ret]))
    
    # è®¡ç®—æ¡ä»¶æ¦‚ç‡ï¼ˆç¤ºä¾‹ï¼Œå…·ä½“å®ç°å–å†³äºCopulaç±»å‹ï¼‰
    # cond_prob = copula_model.cond_cdf(u[:, 0], u[:, 1])
    
    # ç”Ÿæˆä¿¡å·
    # signal = 'long' if cond_prob < 0.05 else 'neutral'
    
    return {'signal': 'neutral', 'confidence': 0.5}
```

**å®æ–½ä¼˜å…ˆçº§**: â­â­â­ (ä¸­ç­‰ä¼˜å…ˆçº§)
- éœ€è¦é¢å¤–çš„ä¾èµ–åº“ï¼ˆcopulaeï¼‰
- è®¡ç®—å¤æ‚åº¦è¾ƒé«˜
- å»ºè®®å…ˆéªŒè¯åŸºç¡€Copulaä¼°è®¡çš„å¯è¡Œæ€§ï¼Œå†è€ƒè™‘ä¿¡å·ç”Ÿæˆ

---

#### ğŸ“ˆ å€Ÿé‰´ç‚¹5: å¼•å…¥é£é™©è°ƒæ•´æ”¶ç›Šè¯„ä¼°

**å½“å‰é—®é¢˜**:
- åªå…³æ³¨ç›¸å…³æ€§æŒ‡æ ‡ï¼Œæ²¡æœ‰è¯„ä¼°ç­–ç•¥çš„å®é™…æ”¶ç›Š
- æ— æ³•é‡åŒ–å¥—åˆ©æœºä¼šçš„æ½œåœ¨æ”¶ç›Šå’Œé£é™©

**æ–‡çŒ®æ–¹æ³•**:
- è®¡ç®—Sharpeæ¯”ç‡ã€æœ€å¤§å›æ’¤ç­‰é£é™©è°ƒæ•´æŒ‡æ ‡
- å¯¹æ¯”ä¸åŒæ–¹æ³•çš„ç­–ç•¥è¡¨ç°

**å®æ–½å»ºè®®**:

```python
class DelayCorrelationAnalyzer:
    def _calculate_risk_metrics(self, returns: np.ndarray) -> dict:
        """
        è®¡ç®—é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡
        
        Args:
            returns: æ”¶ç›Šç‡åºåˆ—ï¼ˆå¯ä»¥æ˜¯æ¨¡æ‹Ÿæ”¶ç›Šæˆ–ä»·å·®æ”¶ç›Šï¼‰
            
        Returns:
            {
                'sharpe_ratio': float,      # Sharpeæ¯”ç‡
                'sortino_ratio': float,     # Sortinoæ¯”ç‡
                'max_drawdown': float,      # æœ€å¤§å›æ’¤
                'annual_return': float,     # å¹´åŒ–æ”¶ç›Šç‡
                'volatility': float         # æ³¢åŠ¨ç‡
            }
        """
        if len(returns) == 0:
            return {'sharpe_ratio': 0.0, 'max_drawdown': 0.0}
        
        # å¹´åŒ–æ”¶ç›Šç‡ï¼ˆå‡è®¾æ—¥é¢‘æ•°æ®ï¼‰
        annual_return = np.mean(returns) * 252
        
        # æ³¢åŠ¨ç‡
        volatility = np.std(returns) * np.sqrt(252)
        
        # Sharpeæ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡ä¸º0ï¼‰
        sharpe_ratio = annual_return / volatility if volatility > 0 else 0.0
        
        # Sortinoæ¯”ç‡ï¼ˆåªè€ƒè™‘ä¸‹è¡Œæ³¢åŠ¨ï¼‰
        downside_returns = returns[returns < 0]
        downside_std = np.std(downside_returns) * np.sqrt(252) if len(downside_returns) > 0 else 0
        sortino_ratio = annual_return / downside_std if downside_std > 0 else 0.0
        
        # æœ€å¤§å›æ’¤
        cumulative = np.cumprod(1 + returns)
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = np.min(drawdown)
        
        return {
            'sharpe_ratio': sharpe_ratio,
            'sortino_ratio': sortino_ratio,
            'max_drawdown': max_drawdown,
            'annual_return': annual_return,
            'volatility': volatility
        }
    
    def _simulate_pair_trading_return(self, btc_prices: np.ndarray, 
                                     alt_prices: np.ndarray,
                                     spread: np.ndarray) -> np.ndarray:
        """
        æ¨¡æ‹Ÿé…å¯¹äº¤æ˜“æ”¶ç›Šï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°ç­–ç•¥çš„æ½œåœ¨æ”¶ç›Š
        å®é™…ä½¿ç”¨æ—¶éœ€è¦æ›´å¤æ‚çš„äº¤æ˜“é€»è¾‘
        
        Args:
            btc_prices: BTCä»·æ ¼åºåˆ—
            alt_prices: å±±å¯¨å¸ä»·æ ¼åºåˆ—
            spread: ä»·å·®åºåˆ—
            
        Returns:
            æ¨¡æ‹Ÿæ”¶ç›Šç‡åºåˆ—
        """
        # ç®€åŒ–çš„äº¤æ˜“è§„åˆ™ï¼ˆéœ€è¦æ ¹æ®å®é™…ç­–ç•¥è°ƒæ•´ï¼‰
        # 1. å½“ä»·å·®åç¦»å‡å€¼è¶…è¿‡2ä¸ªæ ‡å‡†å·®æ—¶å¼€ä»“
        # 2. å½“ä»·å·®å›å½’å‡å€¼æ—¶å¹³ä»“
        
        spread_mean = np.mean(spread)
        spread_std = np.std(spread)
        
        positions = []  # æŒä»“çŠ¶æ€
        returns = []    # æ”¶ç›Šåºåˆ—
        
        for i in range(1, len(spread)):
            # ç®€åŒ–çš„ä¿¡å·ç”Ÿæˆï¼ˆå®é™…éœ€è¦æ›´å¤æ‚çš„é€»è¾‘ï¼‰
            if spread[i-1] > spread_mean + 2 * spread_std:
                # ä»·å·®è¿‡å¤§ï¼Œé¢„æœŸå›å½’ï¼Œåšç©ºä»·å·®
                position = -1
            elif spread[i-1] < spread_mean - 2 * spread_std:
                # ä»·å·®è¿‡å°ï¼Œé¢„æœŸå›å½’ï¼Œåšå¤šä»·å·®
                position = 1
            else:
                position = 0
            
            # è®¡ç®—æ”¶ç›Šï¼ˆç®€åŒ–ï¼‰
            if len(positions) > 0 and positions[-1] != 0:
                # æœ‰æŒä»“æ—¶è®¡ç®—æ”¶ç›Š
                spread_return = (spread[i] - spread[i-1]) / abs(spread[i-1])
                returns.append(positions[-1] * spread_return)
            else:
                returns.append(0.0)
            
            positions.append(position)
        
        return np.array(returns)
```

**é›†æˆå»ºè®®**:
- å¯ä»¥åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„å›æµ‹æ¨¡å—
- åœ¨è¯†åˆ«å¼‚å¸¸å¸ç§åï¼Œè¯„ä¼°è¯¥å¸ç§çš„å†å²ç­–ç•¥è¡¨ç°
- å°†é£é™©è°ƒæ•´æŒ‡æ ‡åŠ å…¥é£ä¹¦å‘Šè­¦ï¼Œå¸®åŠ©è¯„ä¼°å¥—åˆ©æœºä¼šçš„è´¨é‡

---

## ä¸‰ã€å®æ–½ä¼˜å…ˆçº§å»ºè®®

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰

1. **å¼•å…¥Kendall's Ï„** â­â­â­â­â­
   - å®æ–½ç®€å•ï¼Œscipyå·²æœ‰å®ç°
   - å¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥ï¼Œä¸ç°æœ‰Winsorizationäº’è¡¥
   - å¯ä»¥ä½œä¸ºPearsonç›¸å…³ç³»æ•°çš„éªŒè¯æŒ‡æ ‡

2. **å¼•å…¥åæ•´æ£€éªŒ** â­â­â­â­â­
   - æä¾›ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯
   - é¿å…ä¼ªç›¸å…³æ€§
   - ä¸ç°æœ‰é•¿æœŸç›¸å…³æ€§é€»è¾‘å®Œç¾å¥‘åˆ

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆåç»­è€ƒè™‘ï¼‰

3. **ä»·å·®è¿‡ç¨‹åˆ†æ** â­â­â­â­
   - ä¸ºCopulaæ–¹æ³•åšå‡†å¤‡
   - æ›´ç¬¦åˆåæ•´ç†è®º
   - å®æ–½éš¾åº¦ä¸­ç­‰

4. **é£é™©è°ƒæ•´æ”¶ç›Šè¯„ä¼°** â­â­â­â­
   - éœ€è¦æ„å»ºå›æµ‹æ¡†æ¶
   - å¯ä»¥é‡åŒ–å¥—åˆ©æœºä¼šçš„è´¨é‡
   - æœ‰åŠ©äºç­–ç•¥ä¼˜åŒ–

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆé•¿æœŸè§„åˆ’ï¼‰

5. **Copulaæ–¹æ³•** â­â­â­
   - è®¡ç®—å¤æ‚åº¦é«˜
   - éœ€è¦é¢å¤–ä¾èµ–
   - å¯ä»¥å…ˆè¿›è¡Œå¯è¡Œæ€§éªŒè¯

---

## å››ã€å…·ä½“ä»£ç é›†æˆç¤ºä¾‹

### 4.1 æœ€å°åŒ–æ”¹åŠ¨ï¼šåªæ·»åŠ Kendall's Ï„éªŒè¯

```python
# åœ¨ hyperliquid_analyzer.py çš„ DelayCorrelationAnalyzer ç±»ä¸­æ·»åŠ 

from scipy.stats import kendalltau

def find_optimal_delay(self, btc_ret: np.ndarray, alt_ret: np.ndarray, 
                       max_lag: int = 3, enable_outlier_treatment: bool = True,
                       enable_beta_calc: bool = True) -> tuple[int, list, float, float | None]:
    """
    å¯»æ‰¾æœ€ä¼˜å»¶è¿Ÿï¼ˆå¢å¼ºç‰ˆï¼šåŒæ—¶è®¡ç®—Kendall's Ï„ï¼‰
    """
    # ... ç°æœ‰çš„å¼‚å¸¸å€¼å¤„ç†å’Œç›¸å…³ç³»æ•°è®¡ç®—ä»£ç  ...
    
    # æ–°å¢ï¼šè®¡ç®—Kendall's Ï„ä½œä¸ºéªŒè¯
    kendall_tau, kendall_pvalue = kendalltau(
        btc_ret[:-tau_star] if tau_star > 0 else btc_ret,
        alt_ret[tau_star:] if tau_star > 0 else alt_ret
    )
    
    # å¯é€‰ï¼šå°†Kendall's Ï„åŠ å…¥æ—¥å¿—
    logger.debug(
        f"å»¶è¿Ÿä¼˜åŒ– | Ï„*={tau_star} | Pearson={max_corr:.4f} | "
        f"Kendall's Ï„={kendall_tau:.4f} | p={kendall_pvalue:.4f}"
    )
    
    return tau_star, corrs, max_corr, beta
```

### 4.2 ä¸­ç­‰æ”¹åŠ¨ï¼šæ·»åŠ åæ•´æ£€éªŒè¿‡æ»¤

```python
# åœ¨ _detect_anomaly_pattern æ–¹æ³•ä¸­æ·»åŠ åæ•´æ£€éªŒ

from statsmodels.tsa.stattools import coint

def _detect_anomaly_pattern(self, results: list, 
                           btc_prices: np.ndarray = None,
                           alt_prices: np.ndarray = None) -> tuple[bool, float, float, float]:
    """
    å¢å¼ºçš„å¼‚å¸¸æ£€æµ‹ï¼šç»“åˆåæ•´æ£€éªŒ
    """
    # ... ç°æœ‰çš„Betaæ£€æŸ¥å’Œç›¸å…³æ€§åˆ†æä»£ç  ...
    
    # æ–°å¢ï¼šå¦‚æœæœ‰ä»·æ ¼æ•°æ®ï¼Œè¿›è¡Œåæ•´æ£€éªŒ
    if btc_prices is not None and alt_prices is not None:
        try:
            score, pvalue, _ = coint(alt_prices, btc_prices)
            is_cointegrated = pvalue < 0.05
            
            if not is_cointegrated:
                logger.info(
                    f"åæ•´æ£€éªŒæœªé€šè¿‡ï¼Œè¿‡æ»¤ | på€¼: {pvalue:.4f}"
                )
                return False, 0, 0.0, 0.0
        except Exception as e:
            logger.warning(f"åæ•´æ£€éªŒå¤±è´¥: {e}")
            # å¦‚æœæ£€éªŒå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸæœ‰é€»è¾‘
    
    # ... åŸæœ‰çš„å¼‚å¸¸æ¨¡å¼åˆ¤æ–­é€»è¾‘ ...
```

---

## äº”ã€å®æ–½è·¯çº¿å›¾

### ç¬¬ä¸€é˜¶æ®µï¼ˆ1-2å‘¨ï¼‰ï¼šç¨³å¥æ€§å¢å¼º

1. âœ… å¼•å…¥Kendall's Ï„ä½œä¸ºç›¸å…³æ€§éªŒè¯æŒ‡æ ‡
2. âœ… åœ¨æ—¥å¿—ä¸­è¾“å‡ºKendall's Ï„å€¼ï¼Œä¸Pearsonç›¸å…³ç³»æ•°å¯¹æ¯”
3. âœ… éªŒè¯Kendall's Ï„ä¸ç°æœ‰é€»è¾‘çš„ä¸€è‡´æ€§

### ç¬¬äºŒé˜¶æ®µï¼ˆ2-3å‘¨ï¼‰ï¼šç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯

1. âœ… å¼•å…¥Engle-Grangeråæ•´æ£€éªŒ
2. âœ… åœ¨å¼‚å¸¸æ£€æµ‹ä¸­æ·»åŠ åæ•´æ£€éªŒè¿‡æ»¤
3. âœ… å¯¹æ¯”åæ•´æ£€éªŒå‰åçš„ç»“æœå·®å¼‚

### ç¬¬ä¸‰é˜¶æ®µï¼ˆ1ä¸ªæœˆåï¼‰ï¼šæ–¹æ³•è®ºæ‰©å±•

1. âœ… å¼•å…¥ä»·å·®è¿‡ç¨‹åˆ†æ
2. âœ… æ„å»ºåŸºç¡€å›æµ‹æ¡†æ¶
3. âœ… è®¡ç®—é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡

### ç¬¬å››é˜¶æ®µï¼ˆé•¿æœŸï¼‰ï¼šé«˜çº§æ–¹æ³•

1. â³ Copulaæ–¹æ³•å¯è¡Œæ€§éªŒè¯
2. â³ åŸºäºCopulaçš„ä¿¡å·ç”Ÿæˆï¼ˆå¦‚æœå¯è¡Œæ€§éªŒè¯é€šè¿‡ï¼‰

---

## å…­ã€é¢„æœŸæ”¶ç›Š

### 6.1 çŸ­æœŸæ”¶ç›Šï¼ˆ1-2ä¸ªæœˆï¼‰

- **é™ä½å‡é˜³æ€§**: é€šè¿‡åæ•´æ£€éªŒè¿‡æ»¤ä¼ªç›¸å…³æ€§
- **æé«˜ç¨³å¥æ€§**: Kendall's Ï„å¯¹å¼‚å¸¸å€¼æ›´ä¸æ•æ„Ÿ
- **å¢å¼ºå¯ä¿¡åº¦**: ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯æå‡ç»“æœå¯é æ€§

### 6.2 ä¸­æœŸæ”¶ç›Šï¼ˆ3-6ä¸ªæœˆï¼‰

- **é‡åŒ–è¯„ä¼°**: é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡å¸®åŠ©è¯„ä¼°å¥—åˆ©æœºä¼šè´¨é‡
- **æ–¹æ³•è®ºå®Œå–„**: ä»·å·®è¿‡ç¨‹åˆ†ææ›´ç¬¦åˆç†è®ºæ¡†æ¶
- **ç­–ç•¥ä¼˜åŒ–**: åŸºäºå›æµ‹ç»“æœä¼˜åŒ–é˜ˆå€¼å‚æ•°

### 6.3 é•¿æœŸæ”¶ç›Šï¼ˆ6ä¸ªæœˆä»¥ä¸Šï¼‰

- **éçº¿æ€§å»ºæ¨¡**: Copulaæ–¹æ³•æ•æ‰æ›´å¤æ‚çš„ä¾èµ–å…³ç³»
- **ä¿¡å·ä¼˜åŒ–**: åŸºäºCopulaæ¡ä»¶æ¦‚ç‡çš„ç²¾ç¡®ä¿¡å·ç”Ÿæˆ
- **ç³»ç»ŸåŒ–**: ä»ç ”ç©¶å·¥å…·å‘å±•ä¸ºå®Œæ•´çš„äº¤æ˜“ç­–ç•¥æ¡†æ¶

---

## ä¸ƒã€æ³¨æ„äº‹é¡¹

1. **æ•°æ®è¦æ±‚**: åæ•´æ£€éªŒå’ŒCopulaæ–¹æ³•éœ€è¦è¶³å¤Ÿçš„æ•°æ®é‡ï¼ˆå»ºè®®>100ä¸ªæ•°æ®ç‚¹ï¼‰

2. **è®¡ç®—æˆæœ¬**: Copulaæ–¹æ³•è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå¯èƒ½å½±å“å®æ—¶æ€§èƒ½

3. **å‚æ•°è°ƒä¼˜**: æ–°å¼•å…¥çš„æ–¹æ³•éœ€è¦æ ¹æ®å®é™…æ•°æ®è°ƒæ•´å‚æ•°

4. **å‘åå…¼å®¹**: ç¡®ä¿æ–°åŠŸèƒ½ä¸å½±å“ç°æœ‰é€»è¾‘ï¼Œå¯ä»¥ä½œä¸ºå¯é€‰åŠŸèƒ½å¯ç”¨

5. **æ¸è¿›å®æ–½**: å»ºè®®åˆ†é˜¶æ®µå®æ–½ï¼Œæ¯é˜¶æ®µéªŒè¯æ•ˆæœåå†ç»§ç»­

---

## å…«ã€å‚è€ƒèµ„æ–™

1. **Leung & Nguyen (2019)**: Constructing cointegrated cryptocurrency portfolios for statistical arbitrage. Studies in Economics and Finance 36(3):581â€“599

2. **Tadi & Witzany (2025)**: Copula-based trading of cointegrated cryptocurrency Pairs. Financial Innovation 11, 40. https://doi.org/10.1186/s40854-024-00702-7

3. **æŠ€æœ¯æ–‡æ¡£**:
   - `statsmodels`: https://www.statsmodels.org/
   - `scipy.stats.kendalltau`: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html
   - `copulae`: https://copulae.readthedocs.io/

---

*æ–‡æ¡£åˆ›å»ºæ—¥æœŸ: 2025-12-26*
*åŸºäºå½“å‰é¡¹ç›®ä»£ç å’Œæ–‡çŒ®ç ”ç©¶æ•´ç†*


